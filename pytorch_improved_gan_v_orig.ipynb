{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved GAN\n",
    "\n",
    "GAN for semi-supervised learning: feature-matching technique.\n",
    "\n",
    "Original code (theano): https://github.com/openai/improved-gan\n",
    "\n",
    "Paper: https://arxiv.org/abs/1606.03498\n",
    "\n",
    "**Not implemented or different in comparison with original: **\n",
    "\n",
    "* No data-based initialization (from 100 training examples for stats' calculation)\n",
    "* No learning rate decay (from 800 to 1200 epochs)\n",
    "* Batch size is 25 instead of 100 (mainly for faster updating of EMA network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.autograd import Variable\n",
    "from utils import get_data_loaders, plot_grid\n",
    "from utils import log_sum_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0003\n",
    "train_size = 400\n",
    "batch_size = 25\n",
    "z_dim = 100\n",
    "ema_coeff = 0.0001\n",
    "n = 32    # how to resize image\n",
    "num_channels = 3   # img channels\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('use_cuda: {}'.format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((n, n)), transforms.ToTensor(), \n",
    "                              transforms.Lambda(lambda x: x * 2. - 1.)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_data_loaders('cifar10', transform=transform, batch_size=batch_size*2, \n",
    "                                             use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader_ssl, _ = get_data_loaders('cifar10', transform=transform, batch_size=batch_size, \n",
    "                                             use_cuda=use_cuda, train_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        model.weight.data.normal_(0.0, 0.05)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        model.weight.data.normal_(0.0, 0.05)\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find('ConvTranspose2d') != -1:\n",
    "        model.weight.data.normal_(0.0, 0.05)\n",
    "        model.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs, _ = net(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    acc = correct / total\n",
    "    net.train()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_avg_nn(model_avg, model, coeff):\n",
    "    for (na, pa), (n, p) in zip(model_avg.named_parameters(), model.named_parameters()):\n",
    "        pa.data = pa.data * (1 - coeff) + coeff * p.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dc(nn.Module):\n",
    "    def __init__(self, num_channels=3, img_size=(32, 32), num_classes=10):\n",
    "        super(Dc, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            # block 1\n",
    "            weight_norm(nn.Conv2d(in_channels=num_channels, out_channels=96, kernel_size=3, padding=1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=96, out_channels=96, kernel_size=3, padding=1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=96, out_channels=96, kernel_size=3, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            # block 2\n",
    "            weight_norm(nn.Conv2d(in_channels=96, out_channels=192, kernel_size=3, padding=1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=192, out_channels=192, kernel_size=3, padding=1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=192, out_channels=192, kernel_size=3, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            # block 3\n",
    "            weight_norm(nn.Conv2d(in_channels=192, out_channels=192, kernel_size=3)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=192, out_channels=192, kernel_size=1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            weight_norm(nn.Conv2d(in_channels=192, out_channels=192, kernel_size=1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.AvgPool2d(kernel_size=6, stride=1, padding=0), \n",
    "        )\n",
    "        self.logits = weight_norm(nn.Linear(192, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        features = x.view(-1, x.size(1))\n",
    "        logits = self.logits(features)\n",
    "        return logits, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gc(nn.Module):\n",
    "    def __init__(self, dim_z, dim_features=512, num_channels=3):\n",
    "        super(Gc, self).__init__()\n",
    "        self.dim_features = dim_features\n",
    "        self.num_channels = num_channels\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(dim_z, self.dim_features * 4 * 4),\n",
    "            nn.BatchNorm1d(self.dim_features * 4 * 4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.dim_features, self.dim_features // 2, kernel_size=5, stride=2, \n",
    "                               output_padding=1, padding=2),\n",
    "            nn.BatchNorm2d(self.dim_features // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(self.dim_features // 2, self.dim_features // 4, kernel_size=5, stride=2, \n",
    "                                output_padding=1, padding=2),\n",
    "            nn.BatchNorm2d(self.dim_features // 4),\n",
    "            nn.ReLU(),\n",
    "            weight_norm(nn.ConvTranspose2d(self.dim_features // 4, self.num_channels, kernel_size=5, stride=2, \n",
    "                                output_padding=1, padding=2)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x).view(x.size(0), self.dim_features, 4, 4)\n",
    "        img = self.l2(x)\n",
    "        return img   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "D = Dc()\n",
    "D_avg = Dc()\n",
    "G = Gc(z_dim)\n",
    "D.train(), G.train(), D_avg.train()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "D.apply(weights_init)\n",
    "G.apply(weights_init)\n",
    "D_avg.load_state_dict(D.state_dict())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus = nn.Softplus()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if use_cuda:\n",
    "    D.cuda()\n",
    "    G.cuda()\n",
    "    D_avg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_opt = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "G_opt = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0; D_loss: 2.58; G_loss: 0.37; Accuracy: 34.47%; Accuracy Avg: 10.00%;\n",
      "Epoch: 1; D_loss: 2.18; G_loss: 0.24; Accuracy: 41.51%; Accuracy Avg: 10.00%;\n",
      "Epoch: 2; D_loss: 1.99; G_loss: 0.27; Accuracy: 39.25%; Accuracy Avg: 10.15%;\n",
      "Epoch: 3; D_loss: 1.82; G_loss: 0.28; Accuracy: 41.49%; Accuracy Avg: 21.46%;\n",
      "Epoch: 4; D_loss: 1.70; G_loss: 0.27; Accuracy: 41.83%; Accuracy Avg: 25.61%;\n",
      "Epoch: 5; D_loss: 1.57; G_loss: 0.30; Accuracy: 48.51%; Accuracy Avg: 29.35%;\n",
      "Epoch: 6; D_loss: 1.45; G_loss: 0.32; Accuracy: 51.67%; Accuracy Avg: 33.03%;\n",
      "Epoch: 7; D_loss: 1.36; G_loss: 0.32; Accuracy: 46.86%; Accuracy Avg: 36.55%;\n",
      "Epoch: 8; D_loss: 1.28; G_loss: 0.33; Accuracy: 49.44%; Accuracy Avg: 40.12%;\n",
      "Epoch: 9; D_loss: 1.19; G_loss: 0.34; Accuracy: 50.31%; Accuracy Avg: 43.32%;\n",
      "Epoch: 10; D_loss: 1.09; G_loss: 0.34; Accuracy: 51.22%; Accuracy Avg: 45.93%;\n",
      "Epoch: 11; D_loss: 1.03; G_loss: 0.34; Accuracy: 51.61%; Accuracy Avg: 47.62%;\n",
      "Epoch: 12; D_loss: 0.95; G_loss: 0.35; Accuracy: 53.77%; Accuracy Avg: 49.42%;\n",
      "Epoch: 13; D_loss: 0.89; G_loss: 0.35; Accuracy: 51.74%; Accuracy Avg: 50.68%;\n",
      "Epoch: 14; D_loss: 0.82; G_loss: 0.36; Accuracy: 54.17%; Accuracy Avg: 51.56%;\n",
      "Epoch: 15; D_loss: 0.77; G_loss: 0.36; Accuracy: 50.87%; Accuracy Avg: 52.51%;\n",
      "Epoch: 16; D_loss: 0.72; G_loss: 0.37; Accuracy: 56.90%; Accuracy Avg: 53.18%;\n",
      "Epoch: 17; D_loss: 0.69; G_loss: 0.37; Accuracy: 58.03%; Accuracy Avg: 53.68%;\n",
      "Epoch: 18; D_loss: 0.66; G_loss: 0.36; Accuracy: 55.80%; Accuracy Avg: 54.18%;\n",
      "Epoch: 19; D_loss: 0.62; G_loss: 0.36; Accuracy: 58.80%; Accuracy Avg: 54.86%;\n",
      "Epoch: 20; D_loss: 0.60; G_loss: 0.36; Accuracy: 57.12%; Accuracy Avg: 55.29%;\n",
      "Epoch: 21; D_loss: 0.57; G_loss: 0.36; Accuracy: 58.17%; Accuracy Avg: 56.17%;\n",
      "Epoch: 22; D_loss: 0.55; G_loss: 0.35; Accuracy: 58.02%; Accuracy Avg: 56.64%;\n",
      "Epoch: 23; D_loss: 0.54; G_loss: 0.35; Accuracy: 58.47%; Accuracy Avg: 57.19%;\n",
      "Epoch: 24; D_loss: 0.53; G_loss: 0.35; Accuracy: 58.60%; Accuracy Avg: 57.63%;\n",
      "Epoch: 25; D_loss: 0.52; G_loss: 0.33; Accuracy: 57.79%; Accuracy Avg: 58.14%;\n",
      "Epoch: 26; D_loss: 0.50; G_loss: 0.33; Accuracy: 60.56%; Accuracy Avg: 58.46%;\n",
      "Epoch: 27; D_loss: 0.49; G_loss: 0.33; Accuracy: 59.88%; Accuracy Avg: 59.09%;\n",
      "Epoch: 28; D_loss: 0.48; G_loss: 0.33; Accuracy: 61.14%; Accuracy Avg: 59.56%;\n",
      "Epoch: 29; D_loss: 0.47; G_loss: 0.32; Accuracy: 57.98%; Accuracy Avg: 59.92%;\n",
      "Epoch: 30; D_loss: 0.46; G_loss: 0.32; Accuracy: 60.65%; Accuracy Avg: 60.40%;\n",
      "Epoch: 31; D_loss: 0.45; G_loss: 0.32; Accuracy: 63.05%; Accuracy Avg: 60.82%;\n",
      "Epoch: 32; D_loss: 0.45; G_loss: 0.31; Accuracy: 62.32%; Accuracy Avg: 60.98%;\n",
      "Epoch: 33; D_loss: 0.44; G_loss: 0.31; Accuracy: 62.68%; Accuracy Avg: 61.24%;\n",
      "Epoch: 34; D_loss: 0.44; G_loss: 0.30; Accuracy: 63.80%; Accuracy Avg: 61.74%;\n",
      "Epoch: 35; D_loss: 0.44; G_loss: 0.30; Accuracy: 63.64%; Accuracy Avg: 62.02%;\n",
      "Epoch: 36; D_loss: 0.43; G_loss: 0.30; Accuracy: 61.55%; Accuracy Avg: 62.46%;\n",
      "Epoch: 37; D_loss: 0.42; G_loss: 0.29; Accuracy: 61.37%; Accuracy Avg: 62.59%;\n",
      "Epoch: 38; D_loss: 0.42; G_loss: 0.29; Accuracy: 62.67%; Accuracy Avg: 62.71%;\n",
      "Epoch: 39; D_loss: 0.42; G_loss: 0.29; Accuracy: 61.73%; Accuracy Avg: 62.93%;\n",
      "Epoch: 40; D_loss: 0.41; G_loss: 0.28; Accuracy: 60.69%; Accuracy Avg: 63.13%;\n",
      "Epoch: 41; D_loss: 0.40; G_loss: 0.28; Accuracy: 61.12%; Accuracy Avg: 63.38%;\n",
      "Epoch: 42; D_loss: 0.41; G_loss: 0.28; Accuracy: 63.06%; Accuracy Avg: 63.51%;\n"
     ]
    }
   ],
   "source": [
    "# r = real, f = fake, ul = unlabelled, s = sample\n",
    "final_acc = []\n",
    "print()\n",
    "D.zero_grad()\n",
    "G.zero_grad()\n",
    "for ne in range(1000):\n",
    "    c = 0\n",
    "    it = iter(train_loader_ssl)\n",
    "    eloss, gloss = [], []\n",
    "    for x, _ in train_loader:\n",
    "        # setting up input data\n",
    "        x_ul_1 = x[:batch_size]\n",
    "        x_ul_2 = x[batch_size:]\n",
    "        c += 1\n",
    "        if c == len(train_loader_ssl):  # restarting train_loader_ssl\n",
    "            c = 0\n",
    "            it = iter(train_loader_ssl)\n",
    "        z = torch.randn(batch_size, z_dim)\n",
    "        x_l, y_l = next(it)\n",
    "        if use_cuda:\n",
    "            x_l = x_l.cuda()\n",
    "            y_l = y_l.cuda()\n",
    "            x_ul_1 = x_ul_1.cuda()\n",
    "            x_ul_2 = x_ul_2.cuda()\n",
    "            z = z.cuda()\n",
    "        # train discriminator\n",
    "        D_r_l, _ = D(x_l)\n",
    "        D_r_ul, _ = D(x_ul_1)\n",
    "        G_s = G(z)\n",
    "        D_f, _ = D(G_s.detach())\n",
    "        loss_l = criterion(D_r_l, y_l)\n",
    "        ul = log_sum_exp(D_r_ul)\n",
    "        lf = log_sum_exp(D_f)\n",
    "        loss_ul = -ul.mean() + softplus(ul).mean() + softplus(lf).mean()\n",
    "        D_loss = loss_l + 0.5 * loss_ul \n",
    "        D_loss.backward()\n",
    "        D_opt.step()\n",
    "        D.zero_grad()\n",
    "        G.zero_grad()\n",
    "        update_avg_nn(D_avg, D, ema_coeff)         \n",
    "        # train generator\n",
    "        _, layer_r = D(x_ul_2)\n",
    "        _, layer_f = D(G_s)\n",
    "        G_loss = torch.abs(layer_r.detach().mean(dim=0) - layer_f.mean(dim=0)).mean()\n",
    "        G_loss.backward()\n",
    "        G_opt.step()\n",
    "        D.zero_grad()\n",
    "        G.zero_grad()\n",
    "        # stats\n",
    "        eloss.append(D_loss.data.cpu().numpy())\n",
    "        gloss.append(G_loss.data.cpu().numpy())\n",
    "    acc = test(D, test_loader)\n",
    "    acc_avg = test(D_avg, test_loader)\n",
    "    final_acc.append(acc_avg)\n",
    "    print('Epoch: {}; D_loss: {:.2f}; G_loss: {:.2f}; Accuracy: {:.2f}%; Accuracy Avg: {:.2f}%;'\\\n",
    "          .format(ne, np.array(eloss).mean(), np.array(gloss).mean(), acc*100., acc_avg*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 8]\n",
    "G.training = True\n",
    "z = torch.randn(64, z_dim).cuda() \n",
    "vutils.save_image(G(z).data, 'temp.png')\n",
    "img = mpimg.imread('temp.png')\n",
    "plt.imshow(img)\n",
    "G.training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 8]\n",
    "l = next(iter(train_loader))\n",
    "vutils.save_image(l[0], 'temp2.png')\n",
    "img = mpimg.imread('temp2.png')\n",
    "plt.imshow(img)\n",
    "G.training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in list(D_avg.named_parameters()):\n",
    "    print(n, p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
